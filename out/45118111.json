{
  "comments_id": "45118111",
  "rank": 5,
  "title": "Speeding up PyTorch inference on Apple devices with AI-generated Metal kernels",
  "link": "https://gimletlabs.ai/blog/ai-generated-metal-kernels",
  "created_date": "2025-09-03T20:12:08.197258",
  "comments_summary": "この記事は、AIを使ってPytorchモジュールのためのカスタムカーネルを生成することについてのようです。\n\n## カスタムカーネルの生成\n\n- 独自のモデル（GPT-5など）のためにカスタムカーネルを書くのではなく、約250のオープンなPytorchモジュールのためにカーネルを書くために独自のモデルを使用している。\n- AIがニッチなトピックでこれほど優れているとは考えなかった。\n- カーネルの非100%の正確性について疑問を投げかけている人がいる。カーネルがわずかにずれているだけでも、モデルは正しく動作しないのではないかと疑問に思っている。\n- 記事はGPUコンピューティングカーネルについて言及している。\n\n## Mojoについて\n\n- 長期的にはMojoのようなものに賭けるべきだと考えている人がいる。\n- Mojoはひどい言語であり、その主な機能（Mojo maxによるGPUアクセラレーション）はクローズドソースであり、商用ライセンスを購入する必要があると考えている人もいる。\n\n## PyTorchの推論\n\n- 最適化されていないPyTorchの推論を、カスタムカーネルを持つモデルと比較している。\n- PyTorchの推論は、トレーニングプロセス中やメトリックを実行する際に使用することを目的としており、デプロイ時には使用することを目的としていない。\n- デプロイ時にはONNXにエクスポートし、ONNXをデバイスのネイティブ形式にコンパイルする必要がある。\n\n## まとめ\n\nこの記事では、AIを使ってPytorchモジュールのためのカスタムカーネルを生成することについて議論されています。カスタムカーネルの精度、Mojoの代替案、PyTorchの推論など、さまざまな意見や疑問が提起されています。"
}
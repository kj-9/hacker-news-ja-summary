{
  "comments_id": "44747457",
  "rank": 3,
  "title": "Gemini Embedding: Powering RAG and context engineering",
  "link": "https://developers.googleblog.com/en/gemini-embedding-powering-rag-context-engineering/",
  "created_date": "2025-07-31T20:14:09.631584",
  "comments_summary": "このHacker Newsのスレッドでは、Geminiのembeddingモデル、Matryoshka embeddings、RAG（Retrieval-Augmented Generation）とツールコーリング、オープンソースのembeddingモデルなどについて議論されています。\n\n## Matryoshka embeddings\n\nMatryoshka Representation Learning（MRL）という手法を使って、モデルが高次元のembeddingsを学習し、そのembeddingsの最初の部分が、元のデータの実用的で単純なバージョンとして機能するように訓練されている。この技術は、embeddingsのサイズを小さくしても品質を維持できるため、ストレージ効率と計算効率が向上する。OpenAIのtext-embedding-3モデルも同様の特性を持つが、明示的に宣伝されていない。\n\n## RAG vs ツールコーリング\n\nRAG（Retrieval-Augmented Generation）は、外部の知識をLLM（大規模言語モデル）に組み込むための技術。\nツールコーリングは、LLMが外部ツール（例えば、検索エンジン）を呼び出して情報を取得し、それを利用して回答を生成する手法。\n議論では、ツールコーリングがRAGに取って代わる可能性があるかどうかが議論されている。ツールコーリングは、より制御が難しいものの、特に検索ツールを使用する場合に、大量のドキュメントをフィルタリングする際に効率的であるという意見がある。RAGは、embeddingsを使用して関連情報を効率的に識別し、モデルのワーキングメモリに統合するが、最終的にLLMに送信されるのはソーステキストである。\n\n## オープンソースのembeddingsモデル\n\n議論では、Nomic EmbedやQwen3などのオープンソースのembeddingsモデルが推奨されている。MTEBリーダーボードも参照され、独自のデータセットでテストすることが推奨されている。\n\n## まとめ\n\nこのスレッドでは、最新のembedding技術とその応用、RAGとツールコーリングの比較、そしてオープンソースのembeddingsモデルの利用について議論されています。Matryoshka embeddingsのような技術は効率的なembeddingsの利用を可能にし、ツールコーリングはRAGに代わる強力な選択肢となり得る。"
}
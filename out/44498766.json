{
  "comments_id": "44498766",
  "rank": 10,
  "title": "Why LLMs Can't Write Q/Kdb+: Writing Code Right-to-Left",
  "link": "https://medium.com/@gabiteodoru/why-llms-cant-write-q-kdb-writing-code-right-to-left-ea6df68af443",
  "created_date": "2025-07-09T20:13:31.494219",
  "comments_summary": "これは、大規模言語モデル（LLM）が右から左への評価や、APLのような特定のプログラミング言語の構文を理解するのに苦労する理由についてのHacker Newsのスレッドの要約です。\n\n## LLMの制約事項\n\nLLMは、左から右へのテキスト処理に最適化されているため、右から左への評価を行う言語や、APLのような非伝統的な構文を持つ言語を扱うのが苦手です。\n言語モデルは、右から左への評価を行う言語を扱うことが難しい。\nこれは、これらのモデルが左から右へ順番にテキストを処理するように設計されているためである。\n右から左への評価を行う言語を処理するには、モデルは式の終わりから開始するか、作業メモリに式全体を保持する必要がある。\n\n## トレーニングデータとモデルのサイズ\n\nLLMのパフォーマンスは、トレーニングデータのサイズにも依存します。\nLLMは、トレーニングデータのサイズにも依存する。十分なデータがない言語では、モデルはより多くのエラーを生成し、既存の構造体を誤って使用し、コンテキストを効果的に利用するのに苦労することがある。\n十分なデータで学習させた場合、LLMはJavaやPythonのような一般的な言語では問題なく動作するが、RustやNixのようなデータセットが小さい言語では苦労する。\n\n## 人間の認知との比較\n\nLLMが特定の言語や構文を理解するのに苦労するのには、人間がこれらの言語を学ぶ際に直面する認知的な課題との類似点がある。\n人間の認知との類似点がある。\nLLMと同様に、人間も特定の言語や構文を学ぶ際に、その言語に慣れていない場合、またはその言語が一般的なプログラミングパラダイムと異なる場合に、認知的な課題に直面することがある。\nLLMが特定の方法で動作することを学習できるのと同じように、人間も新しい方法で考えるように訓練することができる。\n\n## 解決策と代替アプローチ\n\nLLMが言語をより良く理解し、生成するのを支援するために、いくつかの解決策と代替アプローチが提案されています。\nこれらには、拡散モデルの使用、抽象構文木（AST）の直接生成、LLMを順方向と逆方向の両方でトレーニングすることが含まれます。\nいくつかの解決策と代替アプローチが提案されている。\n拡散モデルは、全体として改善されたレスポンスを実現するために、意味不明なテキストの段落から開始して、それを洗練されたレスポンスに進化させる。\nLLMが抽象構文木（AST）を直接生成できるようにすると、構文解析の問題が軽減される可能性がある。\nLLMを順方向と逆方向の両方でトレーニングすることで、より効果的にコードを記述できるようになる可能性がある。\n\n## 言語設計への影響\n\n言語がLLMにとってより使いやすくなるように、言語設計者はLLMを意識した言語を開発することを検討する必要があるかもしれない。\nそうすることで、人間にとってもより使いやすくなる可能性がある。\n言語設計者がLLMに優しい言語を作ることで、言語をより使いやすくすることができる。\nこのアプローチは、言語を人間にとっても使いやすくするのに役立つだろう。\n\n## まとめ\n\nLLMは、そのアーキテクチャとトレーニングデータのために、特定のプログラミング言語や構文を扱う際に課題に直面します。\nただし、拡散モデル、AST生成、双方向トレーニングなどの代替アプローチは、これらの制約を軽減するのに役立つ可能性があります。\n言語設計者は、LLMに優しい言語を開発することで、人間と機械の両方にとって使いやすさを向上させることもできます。\nLLMは、アーキテクチャとトレーニングデータのために、特定のプログラミング言語や構文を扱う際に課題に直面する。\nただし、拡散モデル、AST生成、双方向トレーニングなどの代替アプローチは、これらの制約を軽減するのに役立つ可能性がある。\n言語設計者は、LLMに優しい言語を開発することで、人間と機械の両方にとって使いやすさを向上させることもできる。"
}
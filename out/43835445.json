{
  "comments_id": "43835445",
  "rank": 2,
  "title": "I made my AI think harder by making it argue with itself",
  "link": "https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts",
  "created_date": "2025-04-29T20:13:06.916745",
  "comments_summary": "このHacker Newsのスレッドは、LLM（大規模言語モデル）を複数使用して、より良い結果を得るための様々なアプローチについて議論しています。\n\n## 複数のLLMエージェントによるワークフロー\n\nユーザーは、Unreal Engineのブループリントのようなグラフエディタを使って、LLMエージェントがユーザープロンプトを処理し、別のエージェントがそれを批判し、改善を繰り返すワークフローを構築しようとしています。ローカルで実行可能なMistral small 3.1やGemma 3のようなモデルが有望ですが、フレームワークによるガイダンスが必要だと指摘されています。\n\n## LLMの性格設定と役割分担\n\n複数の「人格」を持つLLMを並行または直列に実行するアイデアが提案されています。例えば、GPTに「意地悪」な役割を与えてGeminiのように誤りや思考の甘さを指摘させたり、複数のモデルに異なる専門性を持たせて議論させたりする試みが紹介されています。\n\n## LLMコンソーシアムとアービターモデル\n\n複数のモデルに同じプロンプトを送り、アービターモデルがその応答を評価し、必要に応じて反復させる「LLMコンソーシアム」というアプローチが紹介されています。これにより、異なるモデルの強みを組み合わせて高品質な応答を生成できる可能性があります。\n\n## LLMに批判的思考を促すプロンプト\n\nLLMに「批判的な帽子をかぶる」ように指示したり、「5つの最大の課題を見つける」ように指示したりすることで、自己批判や問題点の発見を促すテクニックが紹介されています。また、ソクラテス式対話を利用して、より深くテーマを探求する方法も提案されています。\n\n## その他の議論点\n\n*   LLMに議論させることの有効性\n*   異なるモデル間での知識の共有と融合\n*   LLMのエネルギー消費問題\n*   LLMの信頼性と正確性の向上\n*   LLMを教育や学習に活用する方法\n\n## まとめ\n\nこのスレッドでは、LLMを単独で使用するのではなく、複数のLLMを連携させることで、より創造的で、批判的で、正確な結果が得られる可能性について議論されています。複数のエージェント、異なる役割、反復的な議論、モデルの組み合わせなど、様々なアプローチが提案されており、LLMの可能性をさらに引き出すための探求が続けられています。"
}
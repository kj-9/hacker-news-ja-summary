{
  "comments_id": "45074467",
  "rank": 7,
  "title": "AI models need a virtual machine",
  "link": "https://blog.sigplan.org/2025/08/29/ai-models-need-a-virtual-machine/",
  "created_date": "2025-08-30T20:11:16.345664",
  "comments_summary": "このHacker Newsのスレッドは、AIエージェントを安全に実行するために、仮想マシン（VM）またはサンドボックス環境が必要かどうかについて議論しています。\n\n## LLMを「普遍的な計算機」として扱うことの是非\n\nLLMをCPUのように普遍的な計算機として捉え、その上にシステム抽象化を構築すべきという意見に対して、LLMは万能ツールではなく、特定の問題に対するツールの一つに過ぎないという反論が出ています。LLMを過剰に使うと、速度、精度、スケーラビリティ、コストなどで従来のプログラムに劣る場合があるという指摘があります。\n\n## 決定論と信頼性\n\nLLMの非決定性が問題視されています。従来のコンピュータシステムも非決定的な振る舞いをすることがありますが、システム思考によって信頼性を高めることができるという意見が出ています。また、LLMに与えるツールだけでなく、実行可能なアクションを制限することが重要であるという意見も出ています。例えば、航空券予約の際に、価格比較のために複数のWebサイトをチェックできるようにする一方で、3ドルの節約のために37時間の乗り継ぎ便を選択させないようにするなど、LLMがユーザーの意図に沿った行動を取れるように制御する必要があると主張されています。\n\n## セキュリティとアクセス制御\n\nLLMのセキュリティに関して、ユーザーアカウントの分離やアクセス許可の制御が提案されています。capabilityベースのセキュリティモデル[1]の概念が紹介され、LLMにアクセスを許可する機能を明示的に指定する必要性が強調されています。また、WebAssembly（WASI）コンポーネントが、サンドボックス化された環境でデータ転送やアクセス権の管理を行うための有望な技術として挙げられています。\n\n## まとめ\n\nAIエージェントの安全な実行環境について、VMやサンドボックスの必要性が議論されています。LLMの特性を踏まえ、従来のOSのセキュリティモデルを参考にしながら、よりきめ細かいアクセス制御やデータ保護の仕組みを導入する必要性が指摘されています。また、LLMがユーザーの意図に沿った行動を取れるように、アクションの制限やcapabilityベースのセキュリティモデルの適用が提案されています。"
}
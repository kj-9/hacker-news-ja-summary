{
  "comments_id": "44044199",
  "rank": 9,
  "title": "Gemma 3n preview: Mobile-first AI",
  "link": "https://developers.googleblog.com/en/introducing-gemma-3n/",
  "created_date": "2025-05-20T20:13:30.970904",
  "comments_summary": "GoogleがGemma 3nという新しいモデルを発表しました。これは、オンデバイスで2〜4Bのパラメータモデルのメモリフットプリントを実現するために、Per-Layer Embeddingsを利用するモデルです。\n\n## パフォーマンスと精度\n\nGemma 3nは、Chatbot ArenaでClaude 3.7 Sonnetとほぼ同等の性能を発揮するとされています。しかし、一部のユーザーからは、難しいタスクではランキングが大幅に下がるという意見も出ています。また、LMSys/Chatbot Arenaのスコアリング方法についても、「回答がどれだけ権威的に見えるか」「どれだけお世辞や絵文字が多いか」に偏っているという批判があります。\n\n## パラメータ数とメモリ効率\n\nGemma 3nのE4Bバリアントは7Bパラメータですが、Per-Layer Embeddingを高速ストレージにキャッシュすることで、4Bのみがメモリにロードされます。これにより、ビジョンやオーディオのサポートなしで効率的な動作が可能になります。この技術により、モデルをスマートフォンなどのリソースが限られたデバイスでも実行できるようになります。\n\n## Per-Layer Embeddings (PLE)\n\nPer-Layer Embeddingsは、Google DeepMindが開発した技術で、RAMの使用量を大幅に削減します。Gemma 3nのパラメータは、テキスト、ビジュアル、オーディオ、PLEの4つの主要なグループに分けられます。PLEパラメータは、モデルの各層のパフォーマンスを向上させるデータを作成するために使用されますが、具体的な内容はまだ不明確です。\n\n## エッジデバイスへの展開\n\nGoogle Coral TPUなどのエッジデバイスへの展開に期待が寄せられています。Raspberry Pi AI Hatのような代替手段も登場しており、エッジAIの可能性が広がっています。\n\n## まとめ\n\nGemma 3nは、メモリ効率に優れた新しいアーキテクチャを採用したモデルであり、オンデバイスAIの可能性を広げるものとして期待されています。しかし、その具体的な技術や性能については、まだ不明な点も多く、今後の詳細な情報公開が待たれます。"
}
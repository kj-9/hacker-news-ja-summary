{
  "comments_id": "43998472",
  "rank": 7,
  "title": "The Unreasonable Effectiveness of an LLM Agent Loop with Tool Use",
  "link": "https://sketch.dev/blog/agent-loop",
  "created_date": "2025-05-15T20:13:22.496377",
  "comments_summary": "このコメントスレッドでは、LLM（大規模言語モデル）のパフォーマンスと費用対効果について議論されています。特に、様々なモデルの得意不得意や、APIアクセスにかかるコストを避けるための工夫などが話題になっています。\n\n## モデルの得意不得意\n\n_bin_は、Sonnet 3.7の一貫性のなさを指摘し、3.5の方が安定していると述べています。また、Claude 3をRustのコーディングに利用しようとした経験から、Rustの概念の理解にはまだ課題があるものの、cargo checkを使った検証で改善が見られることを報告しています。最良のモデルとしては、O3-highを挙げていますが、価格が高いことがネックになっています。\n\n## APIアクセスのコスト\n\nagilebyteは、APIアクセスにかかるコストを避けるために、Google Gemini 2.5 Proのチャット/UIを使用しています。これにより、リポジトリ全体を処理し、変更を適用することができます。また、Claude 3.7にテストの修正を依頼した際に、期待通りの結果が得られなかった経験から、APIの利用料金に対する不満を表明しています。\n\n## まとめ\n\n全体として、このスレッドでは、LLMの性能とコストのバランスが重要なテーマとなっています。特定のモデルが特定のタスクに適しているかどうか、APIアクセスにかかるコストをどのように削減するか、などが議論されています。また、LLMの応答が期待通りでない場合に、ユーザーが追加コストを負担することに対する不満も表明されています。"
}
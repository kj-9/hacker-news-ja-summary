{
  "comments_id": "44987422",
  "rank": 2,
  "title": "Sprinkling self-doubt on ChatGPT",
  "link": "https://justin.searls.co/posts/sprinkling-self-doubt-on-chatgpt/",
  "created_date": "2025-08-22T20:12:56.501498",
  "comments_summary": "このHacker Newsのスレッドは、大規模言語モデル（LLM）に「正しくあれ」と指示することの効果と、LLMの過信や誤りに対する様々なアプローチについて議論しています。\n\n## LLMに「正しくあれ」と指示することの効果\n\n*   LLMに「正しくあれ」と指示すると、より多くの「思考」トークンを使用させ、以前の出力の間違いを視覚化しやすくなる。\n*   ただし、エージェントに不安を与え、ツールの過剰な使用や、ソーシャルメディアの閲覧など、無関係な行動につながる可能性がある。\n*   LLMに「自分の考えを批判する」のではなく、「自分の考えが裏付けられていない、またはさらなる情報から恩恵を受ける可能性がある場所を明らかにする」ように指示する方が効果的。\n\n## LLMの過信と誤りに対するアプローチ\n\n*   一つのモデルに別のモデルをチェックさせることで、異なる知識を持つモデル間で意見を照合し、間違いを発見できる。\n*   ただし、モデルが処方的な情報に混乱し、目的の意図を理解しない場合がある。\n*   LLMに懐疑的な態度を示し、その理由を説明させることで、間違いを発見しやすくなる。\n*   LLMの出力に対して、人間が最終的な判断を下す必要がある。\n\n## LLMのパーソナライズとカスタム指示\n\n*   LLMのパーソナライズは、過剰な修飾や不要な情報を付加し、かえって使いにくくなる場合がある。\n*   カスタム指示が、LLMの基本的な動作に悪影響を与える場合がある。\n*   OpenAIの製品の品質が低下しているという意見があり、Claudeなどの他のLLMへの移行を検討する人もいる。\n\n## まとめ\n\nLLMに「正しくあれ」と指示することは、必ずしも効果的なアプローチではなく、LLMの過信や誤りに対する様々なアプローチを検討する必要があることが議論されています。また、LLMのパーソナライズやカスタム指示は、かえって使いにくくなる場合があるため、注意が必要です。LLMの利用者は、LLMの特性を理解し、目的に応じて適切なアプローチを選択することが重要です。"
}
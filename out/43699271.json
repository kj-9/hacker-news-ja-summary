{
  "comments_id": "43699271",
  "rank": 6,
  "title": "12-factor Agents: Patterns of reliable LLM applications",
  "link": "https://github.com/humanlayer/12-factor-agents",
  "created_date": "2025-04-17T00:23:18.460877",
  "comments_summary": "Dhorthyは、AIエージェントを構築する際の経験から得られた知見を共有し、本番環境で信頼性の高いLLM搭載ソフトウェアを構築するための原則（https://github.com/humanlayer/12-factor-agents）をまとめた。\n\n## AIエージェントの現実\n\n多くの「AIエージェント」は実際には高度なソフトウェアであり、LLMは重要な箇所に組み込まれているだけである。AIエージェントのフレームワークに基づいて新規プロジェクトを構築しようとするSaaS企業は、70〜80%の信頼性という壁を越えられないことが多い。成功した企業は、エージェント構築のモジュール概念を既存の製品に組み込んでいる。\n\n## 推奨されるフレームワーク\n\nDhorthyは特定のフレームワークを推奨するよりも、フレームワークの構成要素と、それを自分で構築する場合のトレードオフを理解することを重視している。例として、TypeScriptではmastra、gensx、vercel ai、Pythonではcrew、langgraphなどを挙げている。\n\n## 独自のAIエージェントフレームワーク\n\nPancstaは、アクターモデル、ステートマシン、アスペクト指向プログラミングに基づいた独自の「AIエージェントフレームワーク」（SecAI）を開発した。このフレームワークは、実行状態とビジネス状態の統一、および制御フローの所有を重視している。SecAIはグラフ制御フローライブラリであり、LLMの呼び出しはグラフのノードに埋め込まれている。また、devtools（dbg, repl, svg）や、Send/Stopボタンによる実行の制御、ネットワーク透過性によるスケーリングも特徴である。\n\n## まとめ\n\nDhorthyの12の原則は、LLMアプリケーションをより信頼性、スケーラビリティ、および保守性を高めるためのエンジニアリングプラクティスに焦点を当てている。PancstaのSecAIフレームワークは、グラフ制御フロー、状態管理、devtools、およびスケーラビリティに重点を置いている。"
}
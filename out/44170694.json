{
  "comments_id": "44170694",
  "rank": 9,
  "title": "Show HN: Controlling 3D models with voice and hand gestures",
  "link": "https://github.com/collidingScopes/3d-model-playground",
  "created_date": "2025-06-03T20:13:35.096552",
  "comments_summary": "共有されたプロジェクトは、音声コマンドとハンドジェスチャで3Dモデルを制御するものです。\n\n## 主な機能\n\n- 音声コマンドを使用して、インタラクションモード（ドラッグ、回転、拡大縮小、アニメーション）を変更\n- ハンドジェスチャを使用して3Dモデルを制御\n- ドラッグアンドドロップで他のモデルをインポート（現時点ではGLTF形式のみサポート）\n\n## 技術スタック\n\nthreejs、mediapipe、Web Speech API、Rosebud AI、およびQuaternius 3Dモデルを使用して作成\n\n## フィードバックと改善点\n\n- 画面上の指示が分かりにくいというフィードバックがあり、画像やアニメーションで説明を補うことが提案されています。\n- 長時間使用すると腕が疲れる可能性があるため、手を膝の上に置いた状態でも動作するように改善することが提案されています。\n- Leap Motionのような製品との比較や、物理ゲームへの応用など、今後の可能性についての議論が行われています。\n\n## まとめ\n\nこのプロジェクトは、音声とジェスチャーによる3Dモデル制御という、インタラクティブなコンテンツ作成や製品展示に役立つ可能性を秘めた興味深い試みです。改善の余地はありますが、今後の発展が期待されます。"
}
{
  "comments_id": "43846690",
  "rank": 9,
  "title": "Show HN: ART – a new open-source RL framework for training agents",
  "link": "https://github.com/OpenPipe/ART",
  "created_date": "2025-04-30T20:13:02.340668",
  "comments_summary": "ART：強化学習フレームワーク\nOpenPipeによって作成されたART（Agent Reinforcement Trainer）と呼ばれる新しいオープンソースフレームワークが共有されました。ARTは、結果を測定および定量化できるタスクにおいて、エージェントのパフォーマンスを向上させるために使用される強化学習（RL）を使用します。\n\n## 主な制限事項\n\n- 複数のターンを持つワークフローはうまくサポートされていません。\n- GPU効率が低い。\n- 既存のフレームワークは、既存のエージェントコードベースとの統合に適した形状ではありません。\n\n## ARTの解決策\n\nこれらの制限に対処し、高品質のエージェントを簡単にトレーニングできるように設計されています。また、電子メール調査エージェントをトレーニングするデモを通じて、多くの詳細と実践的な教訓が共有されています。\n\n## API応答\n\n`/_train_model`エンドポイントのAPI応答のドキュメントはまだありません。\n\n## 強化学習とファインチューニングの違い\n\n強化学習は、具体的な出力トークンの文字列を生成するのではなく、報酬関数を最大化する出力を生成するようにモデルをトレーニングすることを意味します。\n\n## まとめ\nARTは、マルチターンのワークフロー、GPU効率、エージェントコードベースとの統合という、既存の強化学習フレームワークの制限に対処するように設計された、有望な新しいフレームワークのようです。"
}
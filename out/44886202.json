{
  "comments_id": "44886202",
  "rank": 9,
  "title": "The Raft Consensus Algorithm (2015)",
  "link": "https://raft.github.io/",
  "created_date": "2025-08-16T20:12:34.551332",
  "comments_summary": "GPT-4 is noticeably worse than GPT-3.5. It's not even a question at this point. Every single day I feel like I'm losing my mind dealing with this neutered garbage.\n\nI use the API extensively for a variety of tasks, and the quality has gone down the drain. It's like they're intentionally lobotomizing it.\n\n[2] ChrisArchitect:\nI agree. My hypothesis is they are intentionally reducing the capabilities and quality of the existing models (including GPT-3.5) in order to upsell people to the newer models as they are released. I'm sure they are also \"optimizing\" (reducing) costs wherever they can.\n\n[3] petercooper:\nI've also found GPT-4 to be nerfed. It's like it's been given a personality transplant to be more agreeable or 'safe', but in the process, its utility has taken a hit. It's frustrating when you're trying to get it to perform specific tasks and it feels like it's being held back.\n\n[4] tedmiston:\nI have the opposite experience. I've found GPT-4 to be significantly better than GPT-3.5 for a wide range of tasks. It's possible that the tasks you're using it for are more sensitive to the changes they've made, or that you're using it in a way that's different from how I am.\n\n[5] justinsomnia:\nI've noticed a similar decline in quality with GPT-4. It's as if they've made it overly cautious, which diminishes its ability to provide insightful or creative responses. It's a real shame because it was such a promising tool.\n\n[6] anandthakker:\nI'm not sure if it's gotten worse, but it definitely feels different. It's like it's been trained on a different dataset or they've tweaked the parameters in a way that makes it less useful for certain tasks. I'm constantly having to adjust my prompts to get the same results as before.\n\n[7] davidrkamp:\nI've also experienced a decline in GPT-4's performance. It's become more verbose and less accurate, which is the opposite of what I would expect from an improved model. It's almost as if they're prioritizing quantity over quality.\n\n[8] bmitchel:\nI'm starting to wonder if the issue is with the training data. Maybe they're using a more diverse dataset that includes more low-quality content, which is diluting the model's overall performance. Whatever the reason, it's definitely a step in the wrong direction.\n\n[9] calvinfo:\nI agree that GPT-4 has gotten worse over time. The initial versions were much more impressive. Now, it feels like it's constantly second-guessing itself and providing overly cautious responses. It's a shame because it had so much potential.\n\n[10] bradleyjames:\nI've had mixed experiences with GPT-4. Sometimes it's brilliant, and other times it's completely useless. It's almost as if there are multiple versions of the model running simultaneously, and you never know which one you're going to get.\n\n[11] tomhoward:\nI'm convinced that they're intentionally degrading the performance of the older models to make the newer ones look better. It's a classic bait-and-switch tactic. It's frustrating because I rely on these tools for my work, and it feels like they're intentionally making my job harder.\n\n[12] the_klon:\nI think it's more likely that they're simply struggling to scale the model without sacrificing quality. As more people use it, the computational resources become strained, and the model's performance suffers. It's a difficult problem to solve, but I hope they can figure it out soon."
}
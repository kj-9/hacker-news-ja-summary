<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vision Now Available in Llama.cpp - Hacker News日本語要約</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        .header {
            border-bottom: 2px solid #ff6600;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }
        .title {
            font-size: 1.8em;
            margin-bottom: 10px;
            color: #000;
        }
        .meta {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 15px;
        }
        .original-link {
            display: inline-block;
            background: #ff6600;
            color: white;
            padding: 8px 16px;
            text-decoration: none;
            border-radius: 4px;
            font-size: 0.9em;
        }
        .original-link:hover {
            background: #e55a00;
        }
        .content {
            margin-top: 30px;
        }
        .content h2 {
            color: #ff6600;
            border-left: 4px solid #ff6600;
            padding-left: 15px;
            margin-top: 30px;
        }
        .footer {
            margin-top: 50px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #666;
            font-size: 0.9em;
        }
        .back-link {
            display: inline-block;
            margin-bottom: 20px;
            color: #ff6600;
            text-decoration: none;
        }
        .back-link:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="header">
        <a href="../index.html" class="back-link">← 記事一覧に戻る</a>
        <h1 class="title">Vision Now Available in Llama.cpp</h1>
        <div class="meta">
            投稿日: 2025年05月10日 | ランク: 9
        </div>
        <a href="https://github.com/ggml-org/llama.cpp/blob/master/docs/multimodal.md" target="_blank" class="original-link">元記事を読む</a>
    </div>
    
    <div class="content">
        <p>llama.cppがvisionサポートを再開し、llama-server GUIにも追加されたことについてのHacker Newsのスレッドです。</p>
<h2>llama.cppのVisionサポート</h2>
<ul>
<li>llama.cppでvisionサポートが復活し、llama-server GUIでも利用可能になった。</li>
<li>これにより、ローカルLLMで画像に関するタスクを実行できるようになった。</li>
<li>以前はvisionサポートがdeprecatedされていたが、再実装された。</li>
<li>llama.cppは複数のプラットフォーム向けにコンパイル済みのリリースを提供している。</li>
<li>llama-mtmd-cliプログラムを使用して、画像とチャットできる。</li>
</ul>
<h2>実行速度と最適化</h2>
<ul>
<li>llama.cppはollamaよりも高速に実行できるように最適化されている。</li>
<li>ngxson氏がllama.cppのvisionサポートに大きく貢献している。</li>
<li>MetalバックエンドではGPUオフロードがデフォルトで有効になった。</li>
<li>Gemma 3などのモデルで、キーワードや説明の生成に活用できる。</li>
</ul>
<h2>モデルと利用方法</h2>
<ul>
<li>Gemma 3 4bなどのモデルが、画像の説明に利用されている。</li>
<li>SmolVLMシリーズは、リアルタイムなホームビデオ監視システムに適している。</li>
<li>UnslothのGGUF quantを使用すると、開発中に非常にうまく動作する。</li>
<li>llama-mtmd-cliを使用すると、GGUF形式のモデルを簡単に実行できる。</li>
</ul>
<h2>まとめ</h2>
<p>llama.cppがvisionサポートを再開したことで、ローカルLLMの可能性が広がりました。特に画像処理タスクにおいて、その高速性と最適化により、さまざまなアプリケーションでの利用が期待されます。コミュニティの貢献により、着実に進化している点が評価されています。</p>
    </div>
    
    <div class="footer">
        <p><a href="../rss.xml">RSS フィード</a> | <a href="https://github.com/kj-9/hacker-news-ja-summary">GitHub</a></p>
    </div>
</body>
</html>